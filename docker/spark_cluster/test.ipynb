{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path[0] = str(Path(sys.path[0]).parent)\n",
    "from utils import create_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark.get_sparkSession(\"testspark\", \"spark://192.168.1.5:7077\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "\n",
    "conf = SparkConf.setAppName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder.appName(\"demo\").master(\"spark://spark-master:7077\").getOrCreate()\n",
    "spark = SparkSession.builder \\\n",
    "            .appName(\"demo\") \\\n",
    "            .master(\"spark://spark-master:7077\") \\\n",
    "            .config(\"spark.hadoop.fs.s3a.access.key\", \"minio_username\") \\\n",
    "            .config(\"spark.hadoop.fs.s3a.secret.key\", \"minio_password\") \\\n",
    "            .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "            .config(\"spark.hadoop.fs.s3a.connection.timeout\", \"600000\") \\\n",
    "            .config(\"spark.sql.debug.maxToStringFields\", \"100\") \\\n",
    "            .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "            .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "            .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"true\") \\\n",
    "            .config(\"fs.s3.aws.credentials.provider\", \"org.apache.hadoop.fs.s3.TemporaryAWSCredentialsProvider\") \\\n",
    "            .config(\"spark.jars\", \"/usr/local/spark/jars/hadoop-aws-3.3.2.jar,/usr/local/spark/jars/aws-java-sdk-bundle-1.11.1026.jar\") \\\n",
    "            .config(\"spark.executor.extraClassPath\", \"/usr/local/spark/jars/hadoop-aws-3.3.2.jar,/usr/local/spark/jars/aws-java-sdk-bundle-1.11.1026.jar\") \\\n",
    "            .config(\"spark.executor.extraLibrary\", \"/usr/local/spark/jars/hadoop-aws-3.3.2.jar,/usr/local/spark/jars/aws-java-sdk-bundle-1.11.1026.jar\") \\\n",
    "            .config(\"spark.driver.extraClassPath\", \"/usr/local/spark/jars/hadoop-aws-3.3.2.jar,/usr/local/spark/jars/aws-java-sdk-bundle-1.11.1026.jar\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player = spark.read \\\n",
    "    .format(\"parquet\") \\\n",
    "    .load(\"s3a://data-lake/sales_summary.parquet\")\n",
    "\n",
    "player.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(\"s3a://data-lake/t.csv\")\n",
    "\n",
    "t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://127.0.0.1:7077\") \\\n",
    "    .appName(\"Demo\") \\\n",
    "    .config(\"spark.blockManager.port\", \"10025\") \\\n",
    "    .config(\"spark.driver.blockManager.port\", \"10026\") \\\n",
    "    .config(\"spark.driver.port\", \"10027\") \\\n",
    "    .config(\"spark.driver.host\", \"192.168.59.1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "# import findspark\n",
    "# findspark.init()\n",
    "# findspark.find()\n",
    "\n",
    "# from \n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://127.0.0.1:7077\") \\\n",
    "    .appName(\"Demo\") \\\n",
    "    .config(\"spark.blockManager.port\", \"10025\") \\\n",
    "    .config(\"spark.driver.blockManager.port\", \"10026\") \\\n",
    "    .config(\"spark.driver.port\", \"10027\") \\\n",
    "    .config(\"spark.driver.host\", \"192.168.59.1\") \\\n",
    "    .config(\"spark.jars\", \"/opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar:/opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar\") \\\n",
    "    .config(\"spark.executor.extraLibrary\", \"/opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar:/opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar\") \\\n",
    "    .config(\"spark.executor.extraClassPath\", \"/opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar:/opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"/opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar:/opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar\") \\\n",
    "    .getOrCreate()\n",
    "# spark = get_spark_context(\"test\")\n",
    "# print(SparkSession.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder\\\n",
    "    .master('spark://localhost:7777')\\\n",
    "    .appName('Demo') \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://127.0.0.1:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minio_username\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minio_password\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.timeout\", \"600000\") \\\n",
    "    .config(\"spark.sql.debug.maxToStringFields\", \"100\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3.aws.credentials.provider\", \"org.apache.hadoop.fs.s3.SimpleAWSCredentialsProvider\") \\\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/hadoop-aws-3.3.2.jar:/opt/spark/jars/aws-java-sdk-bundle-1.12.533.jar:/opt/spark/jars/jets3t-0.9.0.jar\") \\\n",
    "    .config(\"spark.executor.extraLibrary\", \"/opt/spark/jars/hadoop-aws-3.3.2.jar:/opt/spark/jars/aws-java-sdk-bundle-1.12.533.jar:/opt/spark/jars/jets3t-0.9.0.jar\") \\\n",
    "    .config(\"spark.executor.extraClassPath\", \"/opt/spark/jars/hadoop-aws-3.3.2.jar:/opt/spark/jars/aws-java-sdk-bundle-1.12.533.jar:/opt/spark/jars/jets3t-0.9.0.jar\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"/opt/spark/jars/hadoop-aws-3.3.2.jar:/opt/spark/jars/aws-java-sdk-bundle-1.12.533.jar:/opt/spark/jars/jets3t-0.9.0.jar\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# player = spark.read \\\n",
    "#       .format(\"parquet\") \\\n",
    "#       .parquet(\"s3a://data-lake/sales_summary.parquet\")\n",
    "# player.show()\n",
    "\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"./data/ADANIPORTS.csv\")\n",
    "df.show()\n",
    "# from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
